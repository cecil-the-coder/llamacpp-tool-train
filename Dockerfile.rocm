# Template training container with ROCm support for AMD GPUs
# For running on shadow (AMD GPU node)

FROM python:3.11-slim

ARG DEBIAN_FRONTEND=noninteractive

# Install ROCm runtime and build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
        build-essential git wget curl ca-certificates \
        libcurl4-openssl-dev \
        hipblas rocblas hiprand rocrand miopen-hip \
    && rm -rf /var/lib/apt/lists/*

# Set ROCm path
ENV ROCM_PATH=/opt/rocm
ENV PATH="${ROCM_PATH}/bin:${PATH}"
ENV LD_LIBRARY_PATH="${ROCM_PATH}/lib:${LD_LIBRARY_PATH}"

WORKDIR /app

# Clone and build llama.cpp with ROCm support
ARG LLAMACPP_REF=b5399
RUN git clone --depth 1 https://github.com/ggml-org/llama.cpp.git \
    && cd llama.cpp \
    && git fetch --depth 1 origin ${LLAMACPP_REF} \
    && git checkout ${LLAMACPP_REF} \
    && CMAKE_ARGS="-DGGML_HIPBLAS=ON -DCMAKE_C_COMPILER=hipcc -DCMAKE_CXX_COMPILER=hipcc" \
        make llama-server llama-cli -j$(nproc)

# Install Python dependencies for template testing
RUN pip install --no-cache-dir \
    jinja2 \
    openai \
    pyyaml \
    rich \
    pytest \
    pytest-asyncio \
    httpx

# Copy the training framework
COPY template_trainer/ /app/template_trainer/
COPY templates/ /app/templates/
COPY tests/ /app/tests/
COPY run.py /app/

# Create directories for models and results
RUN mkdir -p /models /results

ENV PYTHONUNBUFFERED=1

ENTRYPOINT ["python", "run.py"]
